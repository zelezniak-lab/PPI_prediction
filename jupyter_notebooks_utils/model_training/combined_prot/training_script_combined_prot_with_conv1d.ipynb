{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34491f6c-6440-4d93-82bb-6e7664cbf005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import  confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "456d5718-3845-40f7-b51f-c9c2a3a705be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/anwer/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "Tue Nov 15 08:12:43 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "| N/A   65C    P8    10W /  N/A |     46MiB /  6144MiB |     37%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1132      G   /usr/lib/xorg/Xorg                 45MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03017144-5be8-49eb-adac-4c30fb886064",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame_train = pd.read_csv(\"../../csv_files_new_ppi/training_and_test_set/combined_prot_a_prot_b/combined_embedding_subset_train.csv\")\n",
    "data_frame_test = pd.read_csv(\"../../csv_files_new_ppi/training_and_test_set/combined_prot_a_prot_b/combined_embedding_subset_test.csv\")\n",
    "data_frame_val = pd.read_csv(\"../../csv_files_new_ppi/training_and_test_set/combined_prot_a_prot_b/combined_embedding_subset_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf6d7d49-50e7-45f2-8de0-d3c7882dc7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028385</td>\n",
       "      <td>0.027177</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.020168</td>\n",
       "      <td>-0.004517</td>\n",
       "      <td>0.028336</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>-0.013377</td>\n",
       "      <td>0.032216</td>\n",
       "      <td>0.030635</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037687</td>\n",
       "      <td>-0.020171</td>\n",
       "      <td>-0.009614</td>\n",
       "      <td>-0.032648</td>\n",
       "      <td>-0.023692</td>\n",
       "      <td>-0.014956</td>\n",
       "      <td>-0.001067</td>\n",
       "      <td>-0.031846</td>\n",
       "      <td>0.012538</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015617</td>\n",
       "      <td>-0.001422</td>\n",
       "      <td>-0.013470</td>\n",
       "      <td>0.006397</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>-0.022813</td>\n",
       "      <td>-0.000177</td>\n",
       "      <td>-0.020818</td>\n",
       "      <td>-0.007053</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006055</td>\n",
       "      <td>-0.026670</td>\n",
       "      <td>-0.021014</td>\n",
       "      <td>-0.002191</td>\n",
       "      <td>-0.015441</td>\n",
       "      <td>-0.039538</td>\n",
       "      <td>0.015931</td>\n",
       "      <td>-0.026638</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001469</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.047037</td>\n",
       "      <td>0.032908</td>\n",
       "      <td>0.024164</td>\n",
       "      <td>0.029622</td>\n",
       "      <td>0.009962</td>\n",
       "      <td>-0.017095</td>\n",
       "      <td>0.028200</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062237</td>\n",
       "      <td>-0.021205</td>\n",
       "      <td>-0.018034</td>\n",
       "      <td>-0.044636</td>\n",
       "      <td>-0.003901</td>\n",
       "      <td>0.002548</td>\n",
       "      <td>-0.002773</td>\n",
       "      <td>-0.059739</td>\n",
       "      <td>0.008306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.018104</td>\n",
       "      <td>0.027533</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>-0.021292</td>\n",
       "      <td>0.046611</td>\n",
       "      <td>-0.020751</td>\n",
       "      <td>0.018554</td>\n",
       "      <td>-0.046236</td>\n",
       "      <td>0.027736</td>\n",
       "      <td>-0.018294</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014451</td>\n",
       "      <td>-0.020901</td>\n",
       "      <td>-0.011621</td>\n",
       "      <td>0.030524</td>\n",
       "      <td>0.028947</td>\n",
       "      <td>-0.027071</td>\n",
       "      <td>0.007687</td>\n",
       "      <td>-0.033697</td>\n",
       "      <td>-0.008957</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020711</td>\n",
       "      <td>0.021858</td>\n",
       "      <td>0.035493</td>\n",
       "      <td>0.064109</td>\n",
       "      <td>0.028367</td>\n",
       "      <td>0.025515</td>\n",
       "      <td>0.003727</td>\n",
       "      <td>-0.004875</td>\n",
       "      <td>-0.027814</td>\n",
       "      <td>-0.004117</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077938</td>\n",
       "      <td>-0.015088</td>\n",
       "      <td>0.019681</td>\n",
       "      <td>0.014134</td>\n",
       "      <td>-0.015882</td>\n",
       "      <td>-0.015707</td>\n",
       "      <td>0.023588</td>\n",
       "      <td>-0.047237</td>\n",
       "      <td>-0.009997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>0.002149</td>\n",
       "      <td>-0.005082</td>\n",
       "      <td>-0.007793</td>\n",
       "      <td>0.026073</td>\n",
       "      <td>0.034440</td>\n",
       "      <td>-0.004397</td>\n",
       "      <td>-0.006836</td>\n",
       "      <td>-0.014811</td>\n",
       "      <td>-0.006304</td>\n",
       "      <td>0.018683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029779</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.003734</td>\n",
       "      <td>-0.007455</td>\n",
       "      <td>-0.038037</td>\n",
       "      <td>0.004197</td>\n",
       "      <td>0.008961</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>0.006070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>0.019183</td>\n",
       "      <td>-0.001014</td>\n",
       "      <td>0.008177</td>\n",
       "      <td>0.021608</td>\n",
       "      <td>0.021657</td>\n",
       "      <td>0.020940</td>\n",
       "      <td>-0.008094</td>\n",
       "      <td>-0.014137</td>\n",
       "      <td>-0.031861</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074985</td>\n",
       "      <td>0.019865</td>\n",
       "      <td>-0.023345</td>\n",
       "      <td>-0.061145</td>\n",
       "      <td>-0.017200</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.020019</td>\n",
       "      <td>0.003406</td>\n",
       "      <td>-0.001012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>0.016292</td>\n",
       "      <td>0.026783</td>\n",
       "      <td>-0.000487</td>\n",
       "      <td>-0.003789</td>\n",
       "      <td>0.038305</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>-0.029539</td>\n",
       "      <td>-0.001255</td>\n",
       "      <td>0.032015</td>\n",
       "      <td>0.008985</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057021</td>\n",
       "      <td>-0.008672</td>\n",
       "      <td>-0.024208</td>\n",
       "      <td>-0.076131</td>\n",
       "      <td>-0.034672</td>\n",
       "      <td>-0.019970</td>\n",
       "      <td>0.010658</td>\n",
       "      <td>-0.024751</td>\n",
       "      <td>-0.011714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>-0.030434</td>\n",
       "      <td>0.021819</td>\n",
       "      <td>0.025154</td>\n",
       "      <td>0.032020</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>0.061596</td>\n",
       "      <td>-0.012900</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>-0.008692</td>\n",
       "      <td>0.048690</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038546</td>\n",
       "      <td>-0.053721</td>\n",
       "      <td>-0.008590</td>\n",
       "      <td>0.037416</td>\n",
       "      <td>0.041671</td>\n",
       "      <td>-0.044147</td>\n",
       "      <td>-0.037194</td>\n",
       "      <td>-0.065800</td>\n",
       "      <td>0.031591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0.029924</td>\n",
       "      <td>0.018162</td>\n",
       "      <td>-0.011681</td>\n",
       "      <td>-0.002145</td>\n",
       "      <td>0.018522</td>\n",
       "      <td>-0.012356</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>-0.002019</td>\n",
       "      <td>0.045906</td>\n",
       "      <td>-0.008772</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025333</td>\n",
       "      <td>-0.025723</td>\n",
       "      <td>-0.019077</td>\n",
       "      <td>-0.022872</td>\n",
       "      <td>-0.029329</td>\n",
       "      <td>-0.024372</td>\n",
       "      <td>-0.009729</td>\n",
       "      <td>-0.032329</td>\n",
       "      <td>-0.009086</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.028385  0.027177  0.001707  0.020168 -0.004517  0.028336  0.001413   \n",
       "1      0.015617 -0.001422 -0.013470  0.006397  0.025932 -0.022813 -0.000177   \n",
       "2      0.001469  0.003226  0.004131  0.047037  0.032908  0.024164  0.029622   \n",
       "3      0.018104  0.027533  0.002827 -0.021292  0.046611 -0.020751  0.018554   \n",
       "4      0.020711  0.021858  0.035493  0.064109  0.028367  0.025515  0.003727   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "19995  0.002149 -0.005082 -0.007793  0.026073  0.034440 -0.004397 -0.006836   \n",
       "19996  0.019183 -0.001014  0.008177  0.021608  0.021657  0.020940 -0.008094   \n",
       "19997  0.016292  0.026783 -0.000487 -0.003789  0.038305  0.001881 -0.029539   \n",
       "19998 -0.030434  0.021819  0.025154  0.032020  0.003013  0.061596 -0.012900   \n",
       "19999  0.029924  0.018162 -0.011681 -0.002145  0.018522 -0.012356  0.003815   \n",
       "\n",
       "              7         8         9  ...      1015      1016      1017  \\\n",
       "0     -0.013377  0.032216  0.030635  ... -0.037687 -0.020171 -0.009614   \n",
       "1     -0.020818 -0.007053  0.001988  ... -0.006055 -0.026670 -0.021014   \n",
       "2      0.009962 -0.017095  0.028200  ... -0.062237 -0.021205 -0.018034   \n",
       "3     -0.046236  0.027736 -0.018294  ... -0.014451 -0.020901 -0.011621   \n",
       "4     -0.004875 -0.027814 -0.004117  ... -0.077938 -0.015088  0.019681   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "19995 -0.014811 -0.006304  0.018683  ... -0.029779  0.001915  0.003734   \n",
       "19996 -0.014137 -0.031861  0.004255  ... -0.074985  0.019865 -0.023345   \n",
       "19997 -0.001255  0.032015  0.008985  ... -0.057021 -0.008672 -0.024208   \n",
       "19998  0.001904 -0.008692  0.048690  ... -0.038546 -0.053721 -0.008590   \n",
       "19999 -0.002019  0.045906 -0.008772  ... -0.025333 -0.025723 -0.019077   \n",
       "\n",
       "           1018      1019      1020      1021      1022      1023  label  \n",
       "0     -0.032648 -0.023692 -0.014956 -0.001067 -0.031846  0.012538      1  \n",
       "1     -0.002191 -0.015441 -0.039538  0.015931 -0.026638  0.001783      1  \n",
       "2     -0.044636 -0.003901  0.002548 -0.002773 -0.059739  0.008306      1  \n",
       "3      0.030524  0.028947 -0.027071  0.007687 -0.033697 -0.008957      0  \n",
       "4      0.014134 -0.015882 -0.015707  0.023588 -0.047237 -0.009997      1  \n",
       "...         ...       ...       ...       ...       ...       ...    ...  \n",
       "19995 -0.007455 -0.038037  0.004197  0.008961 -0.000200  0.006070      1  \n",
       "19996 -0.061145 -0.017200  0.000358  0.020019  0.003406 -0.001012      0  \n",
       "19997 -0.076131 -0.034672 -0.019970  0.010658 -0.024751 -0.011714      0  \n",
       "19998  0.037416  0.041671 -0.044147 -0.037194 -0.065800  0.031591      1  \n",
       "19999 -0.022872 -0.029329 -0.024372 -0.009729 -0.032329 -0.009086      1  \n",
       "\n",
       "[20000 rows x 1025 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02db76e3-c49a-4357-9b6d-e7fdb9eb8af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = data_frame_train.copy()\n",
    "train_labels = train_features.pop('label')\n",
    "train_features = np.array(train_features)\n",
    "\n",
    "\n",
    "test_features = data_frame_test.copy()\n",
    "test_labels = test_features.pop('label')\n",
    "test_features = np.array(test_features)\n",
    "\n",
    "val_features = data_frame_val.copy()\n",
    "val_labels = val_features.pop('label')\n",
    "val_features = np.array(val_features)\n",
    "        \n",
    "x_train = train_features\n",
    "y_train = train_labels\n",
    "x_test = test_features\n",
    "y_test = test_labels\n",
    "x_val = val_features\n",
    "y_val = val_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01a817d6-2116-4f4d-be6a-68d5fc0af6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat_train_features = []\n",
    "# concat_test_features = []\n",
    "# for i in train_features:\n",
    "\n",
    "#     concat_train_features.append(i[0:1024] + i[1024:])\n",
    "\n",
    "# for i in test_features:\n",
    "\n",
    "#     concat_test_features.append(i[0:1024] + i[1024:])\n",
    "\n",
    "# x_train = concat_train_features\n",
    "# y_train = train_labels\n",
    "# x_test = concat_test_features[0:5000]\n",
    "# y_test = test_labels[0:5000]\n",
    "# x_val = concat_test_features[5000:10000]\n",
    "# y_val = np.array(test_labels[5000:10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c732469-da2b-479d-9697-e23523522d5f",
   "metadata": {},
   "source": [
    "## 1. Creating Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9af98a5-acca-4344-9f49-e70a5c6503e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "class Data(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "train_data = Data(torch.FloatTensor(x_train), \n",
    "                       torch.FloatTensor(y_train))\n",
    "## test data    \n",
    "    \n",
    "\n",
    "val_data = Data(torch.FloatTensor(x_test), \n",
    "                       torch.FloatTensor(y_test))\n",
    "\n",
    "\n",
    "test_data =  Data(torch.FloatTensor(x_val), \n",
    "                       torch.FloatTensor(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11be1fcf-d881-41b9-9b26-11d7d41d4adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=128, shuffle=True,drop_last=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=128,drop_last=True )\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=128,drop_last=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fdbabc8-1620-413e-abb8-b37a8d82c16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be1a0df-3910-49d7-a874-7868cb0ad901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d8ebbbf-66a8-43e1-b692-d348267452a4",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ac073c4-3ed3-448e-834a-40827fa55a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be5cbac6-904a-4f09-9eda-107547a01b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70ffcfbc-8719-467d-bdd0-104fd7c13b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, embed_dim = 1024):\n",
    "        super(BertClassifier,self).__init__()\n",
    "     \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1  = nn.Conv1d(in_channels = 1,out_channels = 33, kernel_size = 3, stride=1)\n",
    "        self.fc1 = nn.Linear(33726,1024)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=1024)\n",
    "        self.fc1_1 = nn.Linear(1024,1024)\n",
    "#         self.fc2 = nn.Linear(512,256)\n",
    "        \n",
    "        self.fc3 = nn.Linear(1024,64)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=64)\n",
    "        self.fc4 = nn.Linear(64,32)\n",
    "        \n",
    "        self.fc5 = nn.Linear(32,16)\n",
    "        self.fc6 = nn.Linear(16,8)\n",
    "        self.fc7 = nn.Linear(8,1)\n",
    "\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "       \n",
    "        \n",
    "        inputs = inputs.reshape(128,1,1024)\n",
    "        output_conv = self.relu(self.conv1(inputs))\n",
    "        output_conv = output_conv.reshape(128,33726)\n",
    "        output_1 = self.relu(self.fc1(output_conv))\n",
    "        output_1 = self.bn1(output_1)\n",
    "        output_1_1 = self.relu(self.fc1_1(output_1))\n",
    "        output_1_1 = output_1_1 + output_1\n",
    "        \n",
    "        output_2 = self.relu(self.fc3(output_1_1))\n",
    "        output_2  = self.bn2(output_2)\n",
    "        output_3 = self.relu(self.fc4(output_2))\n",
    "        output_4 = self.relu(self.fc5(output_3))\n",
    "        output_5 = self.relu(self.fc6(output_4))\n",
    "        output = self.fc7(output_5)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4298bc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in train_loader:\n",
    "#     print(i[0])\n",
    "#     print(i[0].shape)\n",
    "#     j = i[0].reshape(128,1,1024)\n",
    "#     print(j)\n",
    "#     x = nn.Conv1d(in_channels = 1,out_channels = 33, kernel_size = 3, stride=1)\n",
    "#     conv_out = x(j)\n",
    "#     print(conv_out)\n",
    "#     print(conv_out.shape)\n",
    "#     conv_out = conv_out.reshape(128,33726)\n",
    "#     print(conv_out)\n",
    "#     print(conv_out.shape)\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe432c6",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "634b32d6-9554-4969-abc6-916d55a5b140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initilize_model(learning_rate=0.001):\n",
    "    \"\"\"Instantiate a CNN model and an optimizer.\"\"\"\n",
    "\n",
    "    model = BertClassifier()\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Send model to `device` (GPU/CPU)\n",
    "    model.to(device)\n",
    "    model= nn.DataParallel(model,device_ids = [0])\n",
    "\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = initilize_model()\n",
    "\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d50169c-71e3-4ca2-b236-f1c4d826f850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): BertClassifier(\n",
      "    (relu): ReLU()\n",
      "    (conv1): Conv1d(1, 33, kernel_size=(3,), stride=(1,))\n",
      "    (fc1): Linear(in_features=33726, out_features=1024, bias=True)\n",
      "    (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc1_1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (fc3): Linear(in_features=1024, out_features=64, bias=True)\n",
      "    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (fc4): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (fc5): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (fc6): Linear(in_features=16, out_features=8, bias=True)\n",
      "    (fc7): Linear(in_features=8, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469c9ff1-7b61-4107-9f3c-7307445bbe53",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa89d2d6-610a-4372-be72-a8babdc08b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "def train(model, optimizer, train_dataloader, val_dataloader = None, epochs =10):\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Start training...\\n\")\n",
    "    \n",
    "    # for param in model.bert.parameters():\n",
    "    #     param.requires_grad = False\n",
    "    for epoch_i in range(1,epochs+1):\n",
    "        \n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        \n",
    "        for step,batch in tqdm(enumerate(train_dataloader)):\n",
    "            \n",
    "            inputs, b_labels = tuple(t.to(device) for t in batch)\n",
    "            \n",
    "            # b_input_ids = b_input_ids.reshape((1,24,1000)).squeeze(0)\n",
    "            # b_attn_masks = b_attn_masks.reshape((1,24,1000)).squeeze(0)\n",
    "            b_labels = b_labels.reshape((1,128,1)).squeeze(0)\n",
    "            # print(b_input_1)\n",
    "            model.zero_grad()\n",
    "            \n",
    "            logits = model(inputs)\n",
    "            \n",
    "        #     preds = torch.round(torch.sigmoid(logits))\n",
    "        # # print(preds,b_labels)\n",
    "        #     accuracy = (preds.float() == b_labels.float()).cpu().numpy().mean() * 100\n",
    "        #     print(accuracy)\n",
    "            \n",
    "#             print(b_labels)\n",
    "           \n",
    "            loss = loss_fn(logits,b_labels.float()) \n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            loss.mean().backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "               \n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        \n",
    "    \n",
    "        if val_dataloader is not None:\n",
    "                \n",
    "                val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "\n",
    "                   \n",
    "                if val_accuracy > best_accuracy:\n",
    "                    best_accuracy = val_accuracy\n",
    "                    torch.save({\n",
    "                        'epoch': epoch_i + 1,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'loss': loss_fn,\n",
    "                        }, 'best_conv_model_trained_v2.pth')\n",
    "\n",
    "                # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max',patience = 3)\n",
    "                # scheduler.step(val_accuracy)\n",
    "        print(f\"Epoch: {epoch_i} | Training Loss: {avg_train_loss}  | Validation Loss: {val_loss}  | Accuracy: {val_accuracy:.2f}\")\n",
    "        with open('result.txt', 'a') as f:\n",
    "            print(f\"Epoch: {epoch_i} | Training Loss: {avg_train_loss}  | Validation Loss: {val_loss}  | Accuracy: {val_accuracy:.2f}\", file=f) \n",
    "    print(\"\\n\")\n",
    "    print(f\"Training complete! Best accuracy: {best_accuracy:.2f}%.\")\n",
    "\n",
    "            \n",
    "   \n",
    "\n",
    "\n",
    "def evaluate(model,val_dataloader):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "    for batch in tqdm(val_dataloader):\n",
    "        # Load batch to GPU\n",
    "        inputs, b_labels = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # b_input_ids = b_input_ids.reshape((1,24,1000)).squeeze(0)\n",
    "        # b_attn_masks = b_attn_masks.reshape((1,24,1000)).squeeze(0)\n",
    "        b_labels = b_labels.reshape((1,128,1)).squeeze(0)\n",
    "        with torch.no_grad():\n",
    "                logits = model(inputs)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        loss = loss_fn(logits, b_labels.float())\n",
    "\n",
    "        val_loss.append(loss.item())\n",
    "# # model = BertModel.from_pretrained(\"Rostlab/prot_bert_bfd\")\n",
    "# for i in tqdm(train_dataloader):\n",
    "#     print(i)\n",
    "        preds = torch.round(torch.sigmoid(logits))\n",
    "        # print(preds,b_labels)\n",
    "        accuracy = (preds.float() == b_labels.float()).cpu().numpy().mean() * 100\n",
    "\n",
    "        val_accuracy.append(accuracy)\n",
    "    \n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fad6f83b-b532-45a6-8397-2f80f8b8edd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0.0,amsgrad=True)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), nesterov = True, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "957b9300-65f9-4d32-a67b-327a0c424ba7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [00:05, 30.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 169.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Training Loss: 0.3484171970914572  | Validation Loss: 0.7926900153574736  | Accuracy: 61.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [00:05, 30.31it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 153.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Training Loss: 0.3336101416976024  | Validation Loss: 0.7900539934635162  | Accuracy: 62.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [00:01, 30.23it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_dataloader, val_dataloader, epochs)\u001b[0m\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step,batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(train_dataloader)):\n\u001b[0;32m---> 20\u001b[0m     inputs, b_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# b_input_ids = b_input_ids.reshape((1,24,1000)).squeeze(0)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# b_attn_masks = b_attn_masks.reshape((1,24,1000)).squeeze(0)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     b_labels \u001b[38;5;241m=\u001b[39m b_labels\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step,batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(train_dataloader)):\n\u001b[0;32m---> 20\u001b[0m     inputs, b_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m batch)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# b_input_ids = b_input_ids.reshape((1,24,1000)).squeeze(0)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# b_attn_masks = b_attn_masks.reshape((1,24,1000)).squeeze(0)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     b_labels \u001b[38;5;241m=\u001b[39m b_labels\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, optimizer,train_loader,val_loader,epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457b02cf-2bb0-4e96-819d-44c7f0b352eb",
   "metadata": {},
   "source": [
    "## 4. Evaluating trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6908fa3-7372-4f62-bcee-bb1db54dc600",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"best_conv_model_trained_v2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94df1f92-1851-4920-9699-dbe3dd1e3dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd13966d-8ee0-49d1-adc5-f76d312110f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,val_dataloader):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for batch in tqdm(val_dataloader):\n",
    "        # Load batch to GPU\n",
    "        inputs, b_labels = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # b_input_ids = b_input_ids.reshape((1,24,1000)).squeeze(0)\n",
    "        # b_attn_masks = b_attn_masks.reshape((1,24,1000)).squeeze(0)\n",
    "        b_labels = b_labels.reshape((1,128,1)).squeeze(0)\n",
    "        with torch.no_grad():\n",
    "                logits = model(inputs)\n",
    "        \n",
    "        \n",
    "        \n",
    "        y_true.extend(b_labels)\n",
    "        loss = loss_fn(logits, b_labels.float())\n",
    "\n",
    "        val_loss.append(loss.item())\n",
    "# # model = BertModel.from_pretrained(\"Rostlab/prot_bert_bfd\")\n",
    "# for i in tqdm(train_dataloader):\n",
    "#     print(i)\n",
    "        preds = torch.round(torch.sigmoid(logits))\n",
    "        y_pred.extend(preds)\n",
    "        # print(preds,b_labels)\n",
    "        accuracy = (preds.float() == b_labels.float()).cpu().numpy().mean() * 100\n",
    "\n",
    "        val_accuracy.append(accuracy)\n",
    "    \n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "    return val_loss, val_accuracy, y_true, y_pred \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e577775-c7e7-43be-9e04-e751d5e9508e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 46/46 [00:00<00:00, 163.23it/s]\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy,y_true,y_pred =  evaluate(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce93c0f3-0386-4b56-9a81-caed9c7b1bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.4633152173913"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58a49b01-756e-45d3-a252-19cdcbeb14ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6166724342366924"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac4d7347-051a-40d8-9a0a-ee3671503a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [j[0].cpu() for j in  y_pred]\n",
    "y_true = [j[0].cpu() for j in  y_true]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4adb6c98-158f-475d-82ba-c499f1a95ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "beb89d84-0cb2-4152-9110-a57f7ccad496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7ff91a436e20>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=[1,0])\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "disp.plot(ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85c09591-6456-4e12-b337-a4d4aa0d56b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.pylab import plt\n",
    "# from numpy import arange\n",
    " \n",
    "\n",
    "\n",
    " \n",
    "# # Generate a sequence of integers to represent the epoch numbers\n",
    "# epochs = range(1, 500)\n",
    " \n",
    "# # Plot and label the training and validation loss values\n",
    "# plt.plot(epochs, train_loss_list, label='Training Loss')\n",
    "# plt.plot(epochs, val_values, label='Validation Loss')\n",
    " \n",
    "# # Add in a title and axes labels\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    " \n",
    "# # Set the tick locations\n",
    "# plt.xticks(arange(0, 500,20)\n",
    " \n",
    "# # Display the plot\n",
    "# plt.legend(loc='best')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb16cb3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
