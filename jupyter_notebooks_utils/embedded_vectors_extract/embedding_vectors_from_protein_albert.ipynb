{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49e6c437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AlbertModel, AlbertTokenizer\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4be5bccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a4927392a78461abd12a5dc696fab60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/238k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3122ba415440aca3c88a0af1cfba2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/505 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained(\"Rostlab/prot_albert\", do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81d1c8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eba116683d148fe80d6ecbbd3892e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/897M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_albert were not used when initializing AlbertModel: ['predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight', 'predictions.LayerNorm.bias', 'sop_classifier.classifier.weight', 'predictions.bias', 'sop_classifier.classifier.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AlbertModel.from_pretrained(\"Rostlab/prot_albert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dcc8d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e0f11f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_Example = [\"A E T C Z A O\",\"S K T Z P\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d101a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_Example = [re.sub(r\"[UZOB]\", \"X\", sequence) for sequence in sequences_Example]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6da5e98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anwer/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2302: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ids = tokenizer.batch_encode_plus(sequences_Example, add_special_tokens=True, pad_to_max_length=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18cd1f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(ids['input_ids']).to(device)\n",
    "attention_mask = torch.tensor(ids['attention_mask']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db12a3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    embedding = model(input_ids=input_ids,attention_mask=attention_mask)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42c76414",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = embedding.cpu().numpy()\n",
    "features = [] \n",
    "for seq_num in range(len(embedding)):\n",
    "    seq_len = (attention_mask[seq_num] == 1).sum()\n",
    "    seq_emd = embedding[seq_num][1:seq_len-1]\n",
    "    features.append(seq_emd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3790600d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.0504114 ,  0.01671049, -0.06041686, ...,  0.03879312,\n",
       "          0.06742979, -0.02243829],\n",
       "        [ 0.04481406,  0.02007729, -0.06041646, ...,  0.01449897,\n",
       "          0.07357281, -0.02993694],\n",
       "        [ 0.04433526,  0.02113996, -0.05988096, ...,  0.01485694,\n",
       "          0.07245751, -0.02932365],\n",
       "        ...,\n",
       "        [ 0.04479378,  0.01773688, -0.06211098, ...,  0.01833749,\n",
       "          0.07087199, -0.02901261],\n",
       "        [ 0.03966043,  0.04050677, -0.01892166, ...,  0.02172128,\n",
       "          0.06361923, -0.0444499 ],\n",
       "        [ 0.04467373,  0.028899  , -0.06304027, ...,  0.00830533,\n",
       "          0.08290324, -0.02485269]], dtype=float32),\n",
       " array([[-0.03166272,  0.01354348, -0.02900332, ..., -0.11964942,\n",
       "         -0.11535285,  0.07926516],\n",
       "        [-0.04238589,  0.01891197, -0.02533977, ..., -0.12101973,\n",
       "         -0.10938682,  0.0965146 ],\n",
       "        [-0.04246924,  0.02128097, -0.02400075, ..., -0.12410869,\n",
       "         -0.10866602,  0.10307008],\n",
       "        [-0.0435378 ,  0.02157612, -0.0225751 , ..., -0.12234712,\n",
       "         -0.10860635,  0.09839357],\n",
       "        [-0.04395527,  0.02232329, -0.02410646, ..., -0.1244436 ,\n",
       "         -0.10650276,  0.11278409]], dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec7a80d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
