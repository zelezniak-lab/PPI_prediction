{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee9e6e12",
   "metadata": {},
   "source": [
    "# 1. Importing important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f87afc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdanish2562022\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import timeit\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import  confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from matplotlib.pyplot import figure\n",
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13201b4",
   "metadata": {},
   "source": [
    "# 2. Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b86c4140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv(\"../../csv_files_new_ppi/training_and_test_set/train_set_without_embedding.csv\")\n",
    "test =  pd.read_csv(\"../../csv_files_new_ppi/training_and_test_set/test_set_without_embedding.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "100b971e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100000\n",
       "1     20000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_pos = train[train.label == 1][0:100000]\n",
    "# train_neg = train[train.label == 0][0:100000]\n",
    "# train = pd.concat([train_pos,train_neg])\n",
    "\n",
    "test_pos = test[test.label == 1][0:20000]\n",
    "test_neg = test[test.label ==0][0:len(test_pos)*5]\n",
    "test = pd.concat([test_pos,test_neg])\n",
    "test.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a875593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pos =  test[test.label == 1][0:10000]\n",
    "val_neg =  test[test.label == 0][0:10000]\n",
    "val = pd.concat([val_pos,val_neg])\n",
    "\n",
    "test_pos =  test[test.label == 1][10000:]\n",
    "test_neg =  test[test.label == 0][10000:]\n",
    "test = pd.concat([test_pos,test_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90651964",
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_pos = test_pos\n",
    "bal_neg = test_neg[0:len(bal_pos)]\n",
    "bal_test = pd.concat([bal_pos,bal_neg]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54417de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Test dataset:  100000\n",
      "Size of balanced test dataset:  20000\n"
     ]
    }
   ],
   "source": [
    "# print(\"Size of Train dataset: \", len(train))\n",
    "print(\"Size of Test dataset: \", len(test))\n",
    "print(\"Size of balanced test dataset: \", len(bal_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76efd1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of negative points in test set: 90000\n",
      "Number of positive points in test set: 10000\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of negative points in balance test set: 10000\n",
      "Number of positive points in balanced test set: 10000\n"
     ]
    }
   ],
   "source": [
    "# print(f\"Number of negative points in training set: {train.label.value_counts()[0]}\")\n",
    "# print(f\"Number of positive points in training set: {train.label.value_counts()[1]}\")\n",
    "print(\"----\"*57)\n",
    "print(f\"Number of negative points in test set: {test.label.value_counts()[0]}\")\n",
    "print(f\"Number of positive points in test set: {test.label.value_counts()[1]}\")\n",
    "print(\"----\"*57)\n",
    "print(f\"Number of negative points in balance test set: {bal_test.label.value_counts()[0]}\")\n",
    "print(f\"Number of positive points in balanced test set: {bal_test.label.value_counts()[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbb3682",
   "metadata": {},
   "source": [
    "# 3. Importing embedding vectors from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0de3e5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../pickle/embedding_vectors_pickle/sum_of_amino_acid_vector.pickle\",'rb') as handle:\n",
    "    dc = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b90c8dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein_A</th>\n",
       "      <th>Protein_B</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>PRO_22276</td>\n",
       "      <td>PRO_14600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>PRO_22276</td>\n",
       "      <td>PRO_16483</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>PRO_22276</td>\n",
       "      <td>PRO_16724</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>PRO_22276</td>\n",
       "      <td>PRO_16701</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>PRO_22276</td>\n",
       "      <td>PRO_20052</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41342</th>\n",
       "      <td>PRO_17949</td>\n",
       "      <td>PRO_17041</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41343</th>\n",
       "      <td>PRO_22991</td>\n",
       "      <td>PRO_14178</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41344</th>\n",
       "      <td>PRO_14427</td>\n",
       "      <td>PRO_14994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41345</th>\n",
       "      <td>PRO_10883</td>\n",
       "      <td>PRO_18248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41346</th>\n",
       "      <td>PRO_10227</td>\n",
       "      <td>PRO_201</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Protein_A  Protein_B  label\n",
       "10000  PRO_22276  PRO_14600      1\n",
       "10001  PRO_22276  PRO_16483      1\n",
       "10002  PRO_22276  PRO_16724      1\n",
       "10003  PRO_22276  PRO_16701      1\n",
       "10004  PRO_22276  PRO_20052      1\n",
       "...          ...        ...    ...\n",
       "41342  PRO_17949  PRO_17041      0\n",
       "41343  PRO_22991  PRO_14178      0\n",
       "41344  PRO_14427  PRO_14994      0\n",
       "41345  PRO_10883  PRO_18248      0\n",
       "41346  PRO_10227    PRO_201      0\n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bal_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de026ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_embed(prot_name):\n",
    "    try:\n",
    "        return dc[prot_name]\n",
    "    except:\n",
    "        return np.nan\n",
    "# train['embed_vec_protein_A'] = train[\"Protein_A\"].apply(return_embed)\n",
    "# train['embed_vec_protein_B'] = train[\"Protein_B\"].apply(return_embed)\n",
    "\n",
    "test['embed_vec_protein_A'] = test[\"Protein_A\"].apply(return_embed)\n",
    "test['embed_vec_protein_B'] = test[\"Protein_B\"].apply(return_embed)\n",
    "\n",
    "bal_test['embed_vec_protein_A'] = bal_test[\"Protein_A\"].apply(return_embed)\n",
    "bal_test['embed_vec_protein_B'] = bal_test[\"Protein_B\"].apply(return_embed)\n",
    "\n",
    "\n",
    "# train = train.dropna()\n",
    "test = test.dropna()\n",
    "bal_test = bal_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6302a981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein_A</th>\n",
       "      <th>Protein_B</th>\n",
       "      <th>label</th>\n",
       "      <th>embed_vec_protein_A</th>\n",
       "      <th>embed_vec_protein_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>PRO_22276</td>\n",
       "      <td>PRO_14600</td>\n",
       "      <td>1</td>\n",
       "      <td>[-9.085736, -7.914215, 9.524684, 11.314579, 3....</td>\n",
       "      <td>[3.930407, 3.3734899, -1.3093201, 5.147397, 8....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>PRO_22276</td>\n",
       "      <td>PRO_16483</td>\n",
       "      <td>1</td>\n",
       "      <td>[-9.085736, -7.914215, 9.524684, 11.314579, 3....</td>\n",
       "      <td>[4.8281817, 3.783645, -2.6764274, 10.862015, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>PRO_22276</td>\n",
       "      <td>PRO_16724</td>\n",
       "      <td>1</td>\n",
       "      <td>[-9.085736, -7.914215, 9.524684, 11.314579, 3....</td>\n",
       "      <td>[3.1177008, 4.4391103, 0.7301938, 4.326043, 3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>PRO_22276</td>\n",
       "      <td>PRO_16701</td>\n",
       "      <td>1</td>\n",
       "      <td>[-9.085736, -7.914215, 9.524684, 11.314579, 3....</td>\n",
       "      <td>[-5.249524, -4.1881943, 2.4008715, 7.8188853, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>PRO_22276</td>\n",
       "      <td>PRO_20052</td>\n",
       "      <td>1</td>\n",
       "      <td>[-9.085736, -7.914215, 9.524684, 11.314579, 3....</td>\n",
       "      <td>[-0.5753384, -1.6819302, -0.9292033, 5.057345,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41342</th>\n",
       "      <td>PRO_17949</td>\n",
       "      <td>PRO_17041</td>\n",
       "      <td>0</td>\n",
       "      <td>[-6.190096, -6.1508827, 0.6949791, 9.865855, -...</td>\n",
       "      <td>[-2.8713324, -9.066683, 16.914745, 32.94564, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41343</th>\n",
       "      <td>PRO_22991</td>\n",
       "      <td>PRO_14178</td>\n",
       "      <td>0</td>\n",
       "      <td>[9.497719, 12.145934, -2.1793778, -3.8672795, ...</td>\n",
       "      <td>[9.838891, -0.7991742, -4.987068, -3.1351407, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41344</th>\n",
       "      <td>PRO_14427</td>\n",
       "      <td>PRO_14994</td>\n",
       "      <td>0</td>\n",
       "      <td>[6.223696, -2.806334, -2.2355785, 7.589502, 1....</td>\n",
       "      <td>[0.73823255, -0.7637875, 3.307858, -1.3456984,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41345</th>\n",
       "      <td>PRO_10883</td>\n",
       "      <td>PRO_18248</td>\n",
       "      <td>0</td>\n",
       "      <td>[7.621707, 30.631163, -5.52094, 19.82989, 13.0...</td>\n",
       "      <td>[-3.1174154, -13.68326, 0.55784076, -4.1401277...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41346</th>\n",
       "      <td>PRO_10227</td>\n",
       "      <td>PRO_201</td>\n",
       "      <td>0</td>\n",
       "      <td>[15.33592, 15.755062, -8.747486, 6.0257297, -5...</td>\n",
       "      <td>[7.909336, 24.23035, -10.025925, 14.294017, 36...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Protein_A  Protein_B  label  \\\n",
       "10000  PRO_22276  PRO_14600      1   \n",
       "10001  PRO_22276  PRO_16483      1   \n",
       "10002  PRO_22276  PRO_16724      1   \n",
       "10003  PRO_22276  PRO_16701      1   \n",
       "10004  PRO_22276  PRO_20052      1   \n",
       "...          ...        ...    ...   \n",
       "41342  PRO_17949  PRO_17041      0   \n",
       "41343  PRO_22991  PRO_14178      0   \n",
       "41344  PRO_14427  PRO_14994      0   \n",
       "41345  PRO_10883  PRO_18248      0   \n",
       "41346  PRO_10227    PRO_201      0   \n",
       "\n",
       "                                     embed_vec_protein_A  \\\n",
       "10000  [-9.085736, -7.914215, 9.524684, 11.314579, 3....   \n",
       "10001  [-9.085736, -7.914215, 9.524684, 11.314579, 3....   \n",
       "10002  [-9.085736, -7.914215, 9.524684, 11.314579, 3....   \n",
       "10003  [-9.085736, -7.914215, 9.524684, 11.314579, 3....   \n",
       "10004  [-9.085736, -7.914215, 9.524684, 11.314579, 3....   \n",
       "...                                                  ...   \n",
       "41342  [-6.190096, -6.1508827, 0.6949791, 9.865855, -...   \n",
       "41343  [9.497719, 12.145934, -2.1793778, -3.8672795, ...   \n",
       "41344  [6.223696, -2.806334, -2.2355785, 7.589502, 1....   \n",
       "41345  [7.621707, 30.631163, -5.52094, 19.82989, 13.0...   \n",
       "41346  [15.33592, 15.755062, -8.747486, 6.0257297, -5...   \n",
       "\n",
       "                                     embed_vec_protein_B  \n",
       "10000  [3.930407, 3.3734899, -1.3093201, 5.147397, 8....  \n",
       "10001  [4.8281817, 3.783645, -2.6764274, 10.862015, 8...  \n",
       "10002  [3.1177008, 4.4391103, 0.7301938, 4.326043, 3....  \n",
       "10003  [-5.249524, -4.1881943, 2.4008715, 7.8188853, ...  \n",
       "10004  [-0.5753384, -1.6819302, -0.9292033, 5.057345,...  \n",
       "...                                                  ...  \n",
       "41342  [-2.8713324, -9.066683, 16.914745, 32.94564, -...  \n",
       "41343  [9.838891, -0.7991742, -4.987068, -3.1351407, ...  \n",
       "41344  [0.73823255, -0.7637875, 3.307858, -1.3456984,...  \n",
       "41345  [-3.1174154, -13.68326, 0.55784076, -4.1401277...  \n",
       "41346  [7.909336, 24.23035, -10.025925, 14.294017, 36...  \n",
       "\n",
       "[20000 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bal_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b64e9a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100000/100000 [00:23<00:00, 4204.76it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [00:04<00:00, 4081.31it/s]\n"
     ]
    }
   ],
   "source": [
    "train_features_Protein_A = []\n",
    "train_features_Protein_B = []\n",
    "train_label = []\n",
    "test_features_Protein_A = []\n",
    "test_features_Protein_B = []\n",
    "test_label =[]\n",
    "bal_features_Protein_A = []\n",
    "bal_features_Protein_B = []\n",
    "bal_label = []\n",
    "# for i in tqdm(range(len(train))):\n",
    "#     train_features_Protein_A.append(np.array(train.iloc[i].embed_vec_protein_A))\n",
    "#     train_features_Protein_B.append(np.array(train.iloc[i].embed_vec_protein_B))\n",
    "#     train_label.append(np.array(train.iloc[i].label))\n",
    "    \n",
    "for i in tqdm(range(len(test))):\n",
    "    test_features_Protein_A.append(np.array(test.iloc[i].embed_vec_protein_A))\n",
    "    test_features_Protein_B.append(np.array(test.iloc[i].embed_vec_protein_B))\n",
    "    test_label.append(np.array(test.iloc[i].label))  \n",
    "for i in tqdm(range(len(bal_test))):\n",
    "    \n",
    "    \n",
    "    bal_features_Protein_A.append(np.array(bal_test.iloc[i].embed_vec_protein_A))\n",
    "    bal_features_Protein_B.append(np.array(bal_test.iloc[i].embed_vec_protein_B))\n",
    "    bal_label.append(np.array(bal_test.iloc[i].label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b1f23cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features_Protein_A = np.array(train_features_Protein_A)\n",
    "# train_features_Protein_B = np.array(train_features_Protein_B)\n",
    "# train_label = np.array(train_label)\n",
    "\n",
    "test_features_Protein_A = np.array(test_features_Protein_A)\n",
    "test_features_Protein_B = np.array(test_features_Protein_B)\n",
    "test_label = np.array(test_label)\n",
    "\n",
    "bal_features_Protein_A = np.array(bal_features_Protein_A)\n",
    "bal_features_Protein_B = np.array(bal_features_Protein_B)\n",
    "bal_label = np.array(bal_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d12be4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6833262",
   "metadata": {},
   "source": [
    "# 4. Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fcd522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data_A,X_data_B, y_data):\n",
    "        self.X_data_A = X_data_A\n",
    "        self.X_data_B = X_data_B\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data_A[index],self.X_data_B[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbf7455f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Data at 0x7f056c77b8b0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data = Data(torch.FloatTensor(train_features_Protein_A), torch.FloatTensor(train_features_Protein_B),\n",
    "#                        torch.FloatTensor(train_label))\n",
    "\n",
    "test_data = Data(torch.FloatTensor(test_features_Protein_A), torch.FloatTensor(test_features_Protein_B),\n",
    "                       torch.FloatTensor(test_label))\n",
    "\n",
    "bal_data = Data(torch.FloatTensor(bal_features_Protein_A), torch.FloatTensor(bal_features_Protein_B),\n",
    "                       torch.FloatTensor(bal_label))\n",
    "bal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0f2589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_loader = DataLoader(dataset=train_data, batch_size=512, shuffle=True,drop_last=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=512,shuffle=True,drop_last=True )\n",
    "bal_loader = DataLoader(dataset=bal_data, batch_size=512,shuffle=True,drop_last=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ced5e5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 1024])\n",
      "torch.Size([512, 1024])\n",
      "torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "for i,j,k in test_loader:\n",
    "    print(i.shape)\n",
    "    print(j.shape)\n",
    "    print(k.shape)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070aa937",
   "metadata": {},
   "source": [
    "\n",
    "# 5. Model_testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b44a933",
   "metadata": {},
   "source": [
    "### 5.1  Approach_2_concat_siamese_network_on_sum_(Probert-BFD)\n",
    "<pre>\n",
    "Training Script: Approach_2_concat_siamese_network_on_sum_.ipynb\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "317ccc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self,config, embed_dim =1024):\n",
    "        super(BertClassifier,self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.config = config\n",
    "        self.conv1  = nn.Conv1d(in_channels = 1,out_channels = 33, kernel_size = 10, stride=1)\n",
    "        self.fc1 = nn.Linear(33495,config.dim_1)\n",
    "        self.fully_connected_layers_1 = nn.ModuleList([nn.Linear(config.dim_1*2,config.dim_1*2)\n",
    "                                                    for _ in range(config.layer_fc_1)])\n",
    "        \n",
    "        \n",
    "    \n",
    "        self.fc_2 = nn.Linear(config.dim_1*2,config.dim_2)\n",
    "        self.fully_connected_layers_2 = nn.ModuleList([nn.Linear(config.dim_2,config.dim_2)\n",
    "                                                    for _ in range(config.layer_fc_2)]) \n",
    "        self.bn2 = nn.BatchNorm1d(num_features=config.dim_2)\n",
    "        self.fc3 = nn.Linear(config.dim_2,config.dim_1)\n",
    "        \n",
    "        self.fc4 = nn.Linear(config.dim_1,256)\n",
    "        self.drop = nn.Dropout(p = 0.2)\n",
    "        self.fc5 = nn.Linear(256,128)\n",
    "        self.fc6 = nn.Linear(128,64)\n",
    "        self.fc7 = nn.Linear(64,32)\n",
    "        self.fc8 = nn.Linear(32,16)\n",
    "        self.fc9 = nn.Linear(16,8)\n",
    "        self.fc10 = nn.Linear(8,1)\n",
    "    \n",
    "    def forward(self, inputs_A,inputs_B):\n",
    "        \n",
    "        \n",
    "        inputs_A = inputs_A.reshape(512,1,1024)\n",
    "        output_conv_A = self.relu(self.conv1(inputs_A))\n",
    "        output_conv_A = output_conv_A.reshape(512,33495) \n",
    "        output_A = self.relu(self.fc1(output_conv_A))\n",
    "        \n",
    "        inputs_B = inputs_B.reshape(512,1,1024)\n",
    "        output_conv_B = self.relu(self.conv1(inputs_B))\n",
    "        output_conv_B = output_conv_B.reshape(512,33495) \n",
    "        output_B = self.relu(self.fc1(output_conv_B))\n",
    "        \n",
    "        \n",
    "        output = torch.cat((output_A, output_B),1)\n",
    "        for i in range(self.config.layer_fc_1):\n",
    "            output = self.relu(self.fully_connected_layers_1[i](output))\n",
    "        output = self.relu(self.fc_2(output))\n",
    "        for i in range(self.config.layer_fc_2):\n",
    "            output = self.relu(self.fully_connected_layers_2[i](output))\n",
    "            \n",
    "        output  = self.bn2(output)\n",
    "        output = self.relu(self.fc3(output))\n",
    "        if self.config.dropout:\n",
    "            output = self.drop(output)\n",
    "            \n",
    "        output = self.relu(self.fc4(output))\n",
    "        output = self.relu(self.fc5(output))\n",
    "        output = self.relu(self.fc6(output))\n",
    "        output = self.fc7(output)\n",
    "        output = self.fc8(output)\n",
    "        output = self.fc9(output)\n",
    "        output = self.fc10(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae8abe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(val_dataloader,config):\n",
    "    device = \"cpu\"\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    model = BertClassifier(config)\n",
    "    model.load_state_dict(torch.load(\"best_model_trained_fc_v2.pth\")['model_state_dict'])\n",
    "    model.eval()\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "    for batch in tqdm(val_dataloader):\n",
    "        device = torch.device(\"cpu\")\n",
    "        inputs_A,inputs_B ,b_labels = tuple(t.to(device) for t in batch)\n",
    "        b_labels = b_labels.reshape((1,512,1)).squeeze(0)\n",
    "        with torch.no_grad():\n",
    "                logits = model(inputs_A,inputs_B)\n",
    "        \n",
    "        loss = loss_fn(logits, b_labels.float())\n",
    "        val_loss.append(loss.item())\n",
    "        preds = torch.round(torch.sigmoid(logits))\n",
    "        \n",
    "        accuracy = (preds.float() == b_labels.float()).cpu().numpy().mean() * 100\n",
    "        val_accuracy.append(accuracy)\n",
    "    \n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy,model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "187891f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer_fc_1': 2,\n",
       " 'dim_1': 2048,\n",
       " 'layer_fc_2': 2,\n",
       " 'dim_2': 512,\n",
       " 'dropout': False,\n",
       " 'optimizer': 'adam',\n",
       " 'learning_rate': 7e-05,\n",
       " 'momentum': 0.95,\n",
       " 'weight_decay': 0.01,\n",
       " 'amsgrad': False,\n",
       " 'epochs': 500}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = dict(layer_fc_1 = 2,\n",
    "        dim_1 = 2048,\n",
    "        layer_fc_2 = 2,\n",
    "        dim_2 = 512,\n",
    "        dropout = False,\n",
    "        optimizer = 'adam',\n",
    "        learning_rate = 0.00007,\n",
    "        momentum = 0.95,\n",
    "        weight_decay = 0.01,\n",
    "        amsgrad = False,\n",
    "        epochs = 500)\n",
    "# model = BertClassifier(config)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22c5cbf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.13.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/anwer/Desktop/PPI_prediction/model_training_py/models/wandb/run-20221212_140038-2pdcb5zo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/danish2562022/model_testing_Approach_2_concat_siamese_network_on_sum_/runs/2pdcb5zo\" target=\"_blank\">jolly-thunder-17</a></strong> to <a href=\"https://wandb.ai/danish2562022/model_testing_Approach_2_concat_siamese_network_on_sum_\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 195/195 [03:45<00:00,  1.15s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7f1236818c443f872f4ad4afe654e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='6.829 MB of 405.940 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.0168â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">jolly-thunder-17</strong>: <a href=\"https://wandb.ai/danish2562022/model_testing_Approach_2_concat_siamese_network_on_sum_/runs/2pdcb5zo\" target=\"_blank\">https://wandb.ai/danish2562022/model_testing_Approach_2_concat_siamese_network_on_sum_/runs/2pdcb5zo</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221212_140038-2pdcb5zo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def model_pipeline(config=None):\n",
    "\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"model_testing_Approach_2_concat_siamese_network_on_sum_\", config=config):\n",
    "      # access all HPs through wandb.config, so logging matches execution!\n",
    "      config = wandb.config\n",
    "      for i,j,k in test_loader:\n",
    "          x = (i,j)\n",
    "          \n",
    "      val_loss,val_accuracy,model = evaluate(test_loader,config)\n",
    "      \n",
    "      \n",
    "      torch.onnx.export(model,x, \"model.onnx\")\n",
    "      wandb.save(\"model.onnx\")\n",
    "      return val_loss,val_accuracy,model\n",
    "\n",
    "val_loss,val_accuracy,model = model_pipeline(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2c7af69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 195/195 [03:46<00:00,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "truth = []\n",
    "predicted = []   \n",
    "for inputs_A,inputs_B,b_label in tqdm(test_loader):\n",
    "    b_label = b_label.reshape((1,512,1)).squeeze(0)\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs_A,inputs_B)\n",
    "        \n",
    "    preds = torch.round(torch.sigmoid(logits))\n",
    "    predicted.extend(preds.detach().numpy())\n",
    "    truth.extend(b_label.detach().numpy())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f481f32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99840it [00:00, 536650.06it/s]\n"
     ]
    }
   ],
   "source": [
    "TN = 0\n",
    "FN = 0  \n",
    "TP = 0\n",
    "FP = 0\n",
    "\n",
    "for i,j in tqdm(enumerate(truth)):\n",
    "    if int(j[0]) == 0:\n",
    "        if int(predicted[i][0]) == 0:\n",
    "            TN += 1\n",
    "        else:\n",
    "            FP += 1\n",
    "            \n",
    "    elif int(j[0]) == 1:\n",
    "        if int(predicted[i][0]) == 0:\n",
    "            FN += 1\n",
    "        else:\n",
    "            TP += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b8e8c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Accuracy/Recall/Sensitivity/TPR: 82.50901081297557%\n",
      "Negative Accuracy/Specificity/TNR: 78.29541913368651%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Positive Accuracy/Recall/Sensitivity/TPR: {TP/truth.count(1)*100}%\")\n",
    "print(f\"Negative Accuracy/Specificity/TNR: {TN/truth.count(0)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "185eab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(FP+TN == truth.count(0))\n",
    "assert(FN+TP == truth.count(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7cfcb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPR: 21.704580866313496%\n",
      "FNR: 17.490989187024432%\n"
     ]
    }
   ],
   "source": [
    "false_positive_rate = FP/truth.count(0)\n",
    "false_negative_rate = FN/truth.count(1)\n",
    "print(f\"FPR: {false_positive_rate *100}%\")\n",
    "print(f\"FNR: {false_negative_rate *100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e91fdc",
   "metadata": {},
   "source": [
    "#### Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f49f5e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:40<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "truth = []\n",
    "predicted = []   \n",
    "for inputs_A,inputs_B,b_label in tqdm(bal_loader):\n",
    "    b_label = b_label.reshape((1,512,1)).squeeze(0)\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs_A,inputs_B)\n",
    "        \n",
    "    preds = torch.round(torch.sigmoid(logits))\n",
    "    predicted.extend(preds.detach().numpy())\n",
    "    truth.extend(b_label.detach().numpy())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d4f8f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19968it [00:00, 512143.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Accuracy/Recall/Sensitivity/TPR: 82.55383074611919%\n",
      "Negative Accuracy/Specificity/TNR: 77.91245116698387%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "TN = 0\n",
    "FN = 0  \n",
    "TP = 0\n",
    "FP = 0\n",
    "\n",
    "for i,j in tqdm(enumerate(truth)):\n",
    "    if int(j[0]) == 0:\n",
    "        if int(predicted[i][0]) == 0:\n",
    "            TN += 1\n",
    "        else:\n",
    "            FP += 1\n",
    "            \n",
    "    elif int(j[0]) == 1:\n",
    "        if int(predicted[i][0]) == 0:\n",
    "            FN += 1\n",
    "        else:\n",
    "            TP += 1\n",
    "\n",
    "\n",
    "print(f\"Positive Accuracy/Recall/Sensitivity/TPR: {TP/truth.count(1)*100}%\")\n",
    "print(f\"Negative Accuracy/Specificity/TNR: {TN/truth.count(0)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8e9318a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPR: 22.087548833016125%\n",
      "FNR: 17.44616925388082%\n"
     ]
    }
   ],
   "source": [
    "false_positive_rate = FP/truth.count(0)\n",
    "false_negative_rate = FN/truth.count(1)\n",
    "print(f\"FPR: {false_positive_rate *100}%\")\n",
    "print(f\"FNR: {false_negative_rate *100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4794b2",
   "metadata": {},
   "source": [
    "#### Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c74e0e0",
   "metadata": {},
   "source": [
    "![alt text](model.onnx.svg \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640e8da4",
   "metadata": {},
   "source": [
    "#### Results summary \n",
    "\n",
    "<pre>\n",
    "On highly <b>imbalanced independent test-set</b>(1:20)\n",
    "Positive Accuracy/Recall/Sensitivity/TPR: 82.50901081297557%\n",
    "Negative Accuracy/Specificity/TNR: 78.29541913368651%\n",
    "FPR: 21.704580866313496%\n",
    "FNR: 17.490989187024432%\n",
    "\n",
    "On highly <b>balanced test-set</b>(1:20)\n",
    "Positive Accuracy/Recall/Sensitivity/TPR: 82.55383074611919%\n",
    "Negative Accuracy/Specificity/TNR: 77.91245116698387%\n",
    "FPR: 22.087548833016125%\n",
    "FNR: 17.44616925388082%\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61d0f87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
